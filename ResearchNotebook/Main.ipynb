{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30be91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ADGAT.Model import *\n",
    "from ADGAT.utils import *\n",
    "import pickle\n",
    "import torch\n",
    "from torch import optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb20418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args:\n",
    "device = 0\n",
    "task = 1\n",
    "max_epoch = 300\n",
    "wait_epoch = 30\n",
    "eta = 1e-4\n",
    "lr = 5e-4\n",
    "heads_att = 6\n",
    "hidn_att = 60\n",
    "hidn_rnn = 360\n",
    "weight_constraint = 0 # L2 weight constraint\n",
    "rnn_length = 30\n",
    "dropout = 0.2\n",
    "clip = 0.25\n",
    "infer = 1\n",
    "relation = 'supply'\n",
    "save = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89304192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(DEVICE, relation):\n",
    "    with open('../Data/relations_author_source/x_numerical.pkl', 'rb') as handle:\n",
    "        markets = pickle.load(handle)\n",
    "    with open('../Data/relations_author_source/y_.pkl', 'rb') as handle:\n",
    "        y_load = pickle.load(handle)\n",
    "\n",
    "    markets = markets.astype(np.float64)\n",
    "    x_market = torch.tensor(markets, device=DEVICE)\n",
    "    x_market.to(torch.double)\n",
    "\n",
    "    #\n",
    "    alternatives = np.zeros(list(markets.shape[:-1]) + [1]).astype(np.float64)\n",
    "    x_alternative = torch.tensor(alternatives, device=DEVICE)\n",
    "    x_alternative.to(torch.double)\n",
    "    \n",
    "    if relation != \"None\":\n",
    "        with open('../Data/relations_author_source/' + relation + '_relation.pkl', 'rb') as handle:\n",
    "            relation_static = pickle.load(handle)\n",
    "        relation_static = torch.tensor(relation_static, device=DEVICE)\n",
    "        relation_static.to(torch.double)\n",
    "    else:\n",
    "        relation_static = None\n",
    "    y = torch.tensor(y_load, device=DEVICE)\n",
    "    y = (y>0).to(torch.long)\n",
    "\n",
    "\n",
    "    return x_market, y, x_alternative, relation_static\n",
    "\n",
    "def train(model, x_train, x_alt_train, y_train, relation_static = None):\n",
    "    model.train()\n",
    "    seq_len = len(x_train)\n",
    "    train_seq = list(range(seq_len))[rnn_length:]\n",
    "    random.shuffle(train_seq)\n",
    "    total_loss = 0\n",
    "    total_loss_count = 0\n",
    "    batch_train = 15\n",
    "    for i in tqdm(train_seq):\n",
    "        output = model(x_train[i - rnn_length + 1: i + 1], x_alt_train[i - rnn_length + 1: i + 1],  relation_static = relation_static)\n",
    "        loss = criterion(output, y_train[i])\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        total_loss_count += 1\n",
    "        if total_loss_count % batch_train == batch_train - 1:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    if total_loss_count % batch_train != batch_train - 1:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    return total_loss / total_loss_count\n",
    "\n",
    "def evaluate(model, x_eval, x_alt_eval, y_eval, relation_static = None):\n",
    "    model.eval()\n",
    "    seq_len = len(x_eval)\n",
    "    seq = list(range(seq_len))[rnn_length:]\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for i in seq:\n",
    "        output = model(x_eval[i - rnn_length + 1: i + 1], x_alt_eval[i - rnn_length + 1: i + 1], relation_static = relation_static)\n",
    "        output = output.detach().cpu()\n",
    "        preds.append(np.exp(output.numpy()))\n",
    "        trues.append(y_eval[i].cpu().numpy())\n",
    "    acc, auc = metrics(trues, preds)\n",
    "    return acc,  auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/1339 [00:00<?, ?it/s][W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "  0%|                                                                       | 0/1339 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (424) must match the size of tensor b (198) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/t5/60z7qg7j35x8q19r3y2nngp80000gn/T/ipykernel_40696/3348237279.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[0;31m#train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mMAX_EPOCH\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m     \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mx_sentiment_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     54\u001B[0m     \u001B[0meval_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_auc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_sentiment_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[0mtest_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_auc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_sentiment_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/t5/60z7qg7j35x8q19r3y2nngp80000gn/T/ipykernel_40696/3051996705.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, x_train, x_alt_train, y_train, relation_static)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0mbatch_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m15\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_seq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mrnn_length\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_alt_train\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mrnn_length\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/ADGAT/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/cs7643-final-project/ADGAT/Model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x_market, x_news, relation_static)\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[0mx_s\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;31m##\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0matt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_r\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0matt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mattentions\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_s\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/cs7643-final-project/ADGAT/Model.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[0mx_s\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;31m##\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0matt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_r\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0matt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mattentions\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_s\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/ADGAT/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/cs7643-final-project/ADGAT/Layers.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_s, input_r, relation_static)\u001B[0m\n\u001B[1;32m    156\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_r\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelation_static\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[0;31m# unmasked attention\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0mcoefs_eye\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_relation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_r\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mrelation_static\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0;31m# attribute-mattered propagation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[0mseq_s\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/cs7643-final-project/ADGAT/Layers.py\u001B[0m in \u001B[0;36mget_relation\u001B[0;34m(self, input_r, relation_static)\u001B[0m\n\u001B[1;32m    143\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_revise\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_revise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m198\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m198\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_r\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1.0\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meye\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m198\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m198\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_r\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m         \u001B[0mcoefs_eye\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcoefs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_revise\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcoefs_eye\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (424) must match the size of tensor b (198) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# DEVICE = \"cuda:\" + device\n",
    "DEVICE = \"cpu\"\n",
    "criterion = torch.nn.NLLLoss()\n",
    "set_seed(1017)\n",
    "if relation != \"None\":\n",
    "    static = 1\n",
    "    pass\n",
    "else:\n",
    "    static = 0\n",
    "    relation_static = None\n",
    "# load dataset\n",
    "print(\"loading dataset\")\n",
    "x, y, x_sentiment, relation_static = load_dataset(DEVICE, relation)\n",
    "# hyper-parameters\n",
    "NUM_STOCK = x.size(1)\n",
    "D_MARKET = x.size(2)\n",
    "D_NEWS = x_sentiment.size(2)\n",
    "MAX_EPOCH =  max_epoch\n",
    "infer = infer\n",
    "hidn_rnn = hidn_rnn\n",
    "heads_att = heads_att\n",
    "hidn_att= hidn_att\n",
    "lr = lr\n",
    "rnn_length = rnn_length\n",
    "t_mix = 1\n",
    "#train-test split\n",
    "x_train = x[: -140]\n",
    "x_eval = x[-140 - rnn_length : -70]\n",
    "x_test = x[-70 - rnn_length:]\n",
    "\n",
    "y_train = y[: -140]\n",
    "y_eval = y[-140 - rnn_length : -70]\n",
    "y_test = y[-70 - rnn_length:]\n",
    "\n",
    "x_sentiment_train = x_sentiment[: -140]\n",
    "x_sentiment_eval = x_sentiment[-140 - rnn_length : -70]\n",
    "x_sentiment_test = x_sentiment[-70 - rnn_length:]\n",
    "# initialize\n",
    "best_model_file = 0\n",
    "epoch = 0\n",
    "wait_epoch = 0\n",
    "eval_epoch_best = 0\n",
    "\n",
    "model = AD_GAT(num_stock=NUM_STOCK, d_market = D_MARKET,d_news= D_NEWS,\n",
    "                  d_hidden = D_MARKET, hidn_rnn = hidn_rnn, heads_att = heads_att,\n",
    "                  hidn_att= hidn_att, dropout = dropout,t_mix = t_mix,\n",
    "                  infer = infer, relation_static = static)\n",
    "# model.cuda(device=DEVICE)\n",
    "model.to(torch.double)\n",
    "optimizer = optim.Adam(model.parameters(), lr= lr, weight_decay=weight_constraint)\n",
    "#train\n",
    "while epoch < MAX_EPOCH:\n",
    "    train_loss = train(model, x_train,x_sentiment_train, y_train, relation_static = relation_static)\n",
    "    eval_acc, eval_auc = evaluate(model, x_eval, x_sentiment_eval, y_eval, relation_static = relation_static)\n",
    "    test_acc, test_auc = evaluate(model, x_test, x_sentiment_test, y_test, relation_static = relation_static)\n",
    "    eval_str = \"epoch{}, train_loss{:.4f}, eval_auc{:.4f}, eval_acc{:.4f}, test_auc{:.4f},test_acc{:.4f}\".format(epoch, train_loss, eval_auc, eval_acc, test_auc, test_acc)\n",
    "    print(eval_str)\n",
    "\n",
    "    if eval_auc > eval_epoch_best:\n",
    "        eval_epoch_best = eval_auc\n",
    "        eval_best_str = \"epoch{}, train_loss{:.4f}, eval_auc{:.4f}, eval_acc{:.4f}, test_auc{:.4f},test_acc{:.4f}\".format(epoch, train_loss, eval_auc,eval_acc, test_auc, test_acc)\n",
    "        wait_epoch = 0\n",
    "        if save:\n",
    "            if best_model_file:\n",
    "                os.remove(best_model_file)\n",
    "            best_model_file = \"./SavedModels/eval:auc{}_acc{}_test:auc{}_acc{}\".format(eval_auc, eval_acc, test_auc, test_acc)\n",
    "            torch.save(model.state_dict(), best_model_file)\n",
    "    else:\n",
    "        wait_epoch += 1\n",
    "\n",
    "    if wait_epoch > 50:\n",
    "        print(\"saved_model_result:\",eval_best_str)\n",
    "        break\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d75f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bce97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_static.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sentiment_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da8be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADGAT",
   "language": "python",
   "name": "adgat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}